digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140348614688016 [label="
 ()" fillcolor=darkolivegreen1]
	140348618323424 [label=NllLossBackward0]
	140348618323328 -> 140348618323424
	140348618323328 [label=LogSoftmaxBackward0]
	140348618323472 -> 140348618323328
	140348618323472 [label=IndexBackward0]
	140348618323184 -> 140348618323472
	140348618323184 [label=SliceBackward0]
	140348618323376 -> 140348618323184
	140348618323376 [label=AddBackward0]
	140348618324000 -> 140348618323376
	140348618324000 [label=AddmmBackward0]
	140348618325392 -> 140348618324000
	140348618149776 [label="classifier.layers.1.lin_l.bias
 (7)" fillcolor=lightblue]
	140348618149776 -> 140348618325392
	140348618325392 [label=AccumulateGrad]
	140348618322992 -> 140348618324000
	140348618322992 [label=DivBackward0]
	140348618322704 -> 140348618322992
	140348618322704 [label=ScatterAddBackward0]
	140348618325056 -> 140348618322704
	140348618325056 [label=IndexSelectBackward0]
	140348618325248 -> 140348618325056
	140348618325248 [label=NativeDropoutBackward0]
	140348618322224 -> 140348618325248
	140348618322224 [label=ReluBackward0]
	140348618323616 -> 140348618322224
	140348618323616 [label=AddBackward0]
	140348618322800 -> 140348618323616
	140348618322800 [label=AddmmBackward0]
	140348618324864 -> 140348618322800
	140348618153232 [label="classifier.layers.0.lin_l.bias
 (64)" fillcolor=lightblue]
	140348618153232 -> 140348618324864
	140348618324864 [label=AccumulateGrad]
	140348618325776 -> 140348618322800
	140348618325776 [label=TBackward0]
	140348618324816 -> 140348618325776
	140348618152832 [label="classifier.layers.0.lin_l.weight
 (64, 1433)" fillcolor=lightblue]
	140348618152832 -> 140348618324816
	140348618324816 [label=AccumulateGrad]
	140348618325584 -> 140348618323616
	140348618325584 [label=MmBackward0]
	140348618325680 -> 140348618325584
	140348618325680 [label=TBackward0]
	140348618322368 -> 140348618325680
	140348618152992 [label="classifier.layers.0.lin_r.weight
 (64, 1433)" fillcolor=lightblue]
	140348618152992 -> 140348618322368
	140348618322368 [label=AccumulateGrad]
	140348618323280 -> 140348618324000
	140348618323280 [label=TBackward0]
	140348618323712 -> 140348618323280
	140348618149696 [label="classifier.layers.1.lin_l.weight
 (7, 64)" fillcolor=lightblue]
	140348618149696 -> 140348618323712
	140348618323712 [label=AccumulateGrad]
	140348618322656 -> 140348618323376
	140348618322656 [label=MmBackward0]
	140348618325248 -> 140348618322656
	140348618324720 -> 140348618322656
	140348618324720 [label=TBackward0]
	140348618325344 -> 140348618324720
	140348618149456 [label="classifier.layers.1.lin_r.weight
 (7, 64)" fillcolor=lightblue]
	140348618149456 -> 140348618325344
	140348618325344 [label=AccumulateGrad]
	140348618323424 -> 140348614688016
}
